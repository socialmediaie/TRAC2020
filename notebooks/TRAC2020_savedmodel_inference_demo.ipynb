{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TRAC2020_savedmodel_inference_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPi8GHT2mCPwU8v0D/897bG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/napsternxg/TRAC2020/blob/master/notebooks/TRAC2020_savedmodel_inference_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko7wu5KaS4hX",
        "colab_type": "code",
        "outputId": "61d11d60-e4a3-4213-cf04-637018a3da54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "%%bash\n",
        "pip install torch transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.90)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_fIY0WMVq09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from scipy.special import softmax\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from collections import defaultdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds0cf9OJkHwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lang, task, base_model = \"ALL\", \"Sub-task C\", \"bert-base-multilingual-uncased\"\n",
        "# socialmediaie/TRAC2020_ALL_C_bert-base-multilingual-uncased\n",
        "# Since all models are on https://huggingface.co/socialmediaie\n",
        "# You need not require using the databank_model\n",
        "# The databank model includes:\n",
        "# the model predictions on TRAC datasets and eval metrics\n",
        "# Tensorboard events file.\n",
        "databank_model = False \n",
        "\n",
        "tar_file = Path(f\"./{lang}_{task}_{base_model}.tar.gz\")\n",
        "if databank_model:\n",
        "  databank_url = \"https://databank.illinois.edu/datafiles/sk3r0/download\"\n",
        "  !mkdir -p \"databank_model\"\n",
        "  if not tar_file.exists():\n",
        "    !curl -JLO \"{databank_url}\"\n",
        "  print(tar_file.exists(), tar_file.absolute())\n",
        "  ! tar -xzf \"./{tar_file}\" -C \"./databank_model\"\n",
        "  ! pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8fVPROXLMed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TASK_LABEL_IDS = {\n",
        "    \"Sub-task A\": [\"OAG\", \"NAG\", \"CAG\"],\n",
        "    \"Sub-task B\": [\"GEN\", \"NGEN\"],\n",
        "    \"Sub-task C\": [\"OAG-GEN\", \"OAG-NGEN\", \"NAG-GEN\", \"NAG-NGEN\", \"CAG-GEN\", \"CAG-NGEN\"]\n",
        "}\n",
        "\n",
        "def get_model(lang, task, base_model, databank_model=False):\n",
        "  # other option is hugging face library\n",
        "  if databank_model:\n",
        "      # Make sure you have downloaded the required model file from https://databank.illinois.edu/datasets/IDB-8882752\n",
        "      # Unzip the file at some model_path (we are using: \"databank_model\")\n",
        "      model_path = Path(f\"./databank_model/{lang}/{task}/output/{base_model}/model\")\n",
        "      print(model_path)\n",
        "      # Assuming you get the following type of structure inside \"databank_model\"\n",
        "      # 'databank_model/ALL/Sub-task C/output/bert-base-multilingual-uncased/model'\n",
        "      #_, lang, task, _, base_model, _ = model_path.parts\n",
        "      tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "      model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "  else:\n",
        "      #lang, task, base_model = \"ALL\", \"Sub-task C\", \"bert-base-multilingual-uncased\"\n",
        "      base_model = f\"socialmediaie/TRAC2020_{lang}_{task.split()[-1]}_{base_model}\"\n",
        "      print(base_model)\n",
        "      tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "      model = AutoModelForSequenceClassification.from_pretrained(base_model)\n",
        "  return model, tokenizer\n",
        "\n",
        "\n",
        "def compute_dict_marginals(pred_probs, task_labels):\n",
        "  task_preds = defaultdict(lambda: defaultdict(float))\n",
        "  for l, p in zip(task_labels, preds_probs):\n",
        "    for i, lt in enumerate(l.split(\"-\")):\n",
        "      task_preds[f\"task_{i}\"][lt] += p\n",
        "  task_preds[\"task_joint\"] = dict(zip(task_labels, pred_probs))\n",
        "  return task_preds\n",
        "\n",
        "def add_marginals(df):\n",
        "  df[\"task_0\"] = df.sum(axis=1)\n",
        "  df.loc[\"task_1\"] = df.sum(axis=0)\n",
        "  return df\n",
        "\n",
        "def show_marginal_probs(pred_probs, task_labels):\n",
        "  df_t = pd.DataFrame({\n",
        "    \"labels\": task_labels,\n",
        "    \"probs\": pred_probs\n",
        "  }).assign(\n",
        "      task_0=lambda x: x[\"labels\"].str.split(\"-\", expand=True)[0],\n",
        "      task_1=lambda x: x[\"labels\"].str.split(\"-\", expand=True)[1]\n",
        "  ).drop(\"labels\", axis=1).pivot_table(index=\"task_0\", columns=\"task_1\", values=\"probs\", aggfunc=\"first\").pipe(add_marginals)\n",
        "  return df_t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yWT3lOolNST",
        "colab_type": "code",
        "outputId": "a4dc13d3-a822-4211-80d3-44c0c2decc02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model, tokenizer = get_model(lang, task, base_model, databank_model=databank_model)\n",
        "# For doing inference set model in eval mode\n",
        "model.eval();"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "socialmediaie/TRAC2020_ALL_C_bert-base-multilingual-uncased\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8hPKewhY_c2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sentence = \"This is a good cat and this is a bad dog.\"\n",
        "sentence = \"What a vacuum minded witch, product of May be so called Ranga-Billa. Such mean people gets Bookers Award, Disgusting!\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vBA_jrEZD23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you want to further fine-tune the model you can reset the model to model.train()\n",
        "task_labels = TASK_LABEL_IDS[task]\n",
        "\n",
        "processed_sentence = f\"{tokenizer.cls_token} {sentence}\"\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
        "tokens_tensor = torch.tensor([indexed_tokens])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuPbUoxLab5G",
        "colab_type": "code",
        "outputId": "65b0ecd5-1095-4214-91aa-67c3820b4888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "  logits, = model(tokens_tensor, labels=None)\n",
        "logits"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4.4276,  0.9031,  0.1941, -1.8775, -0.0150, -1.7862]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlYkk8j1pF8c",
        "colab_type": "code",
        "outputId": "b26f64ae-92f2-4dfe-9786-cb6770836449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "preds = logits.detach().cpu().numpy()\n",
        "preds_probs = softmax(preds, axis=1)\n",
        "preds = np.argmax(preds_probs, axis=1)\n",
        "preds_labels = np.array(task_labels)[preds]\n",
        "print(f\"Predicted: {preds_labels[0]}\")\n",
        "print(f\"Probabilities: \")\n",
        "dict(zip(task_labels, preds_probs[0]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted: OAG-GEN\n",
            "Probabilities: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CAG-GEN': 0.011104056,\n",
              " 'CAG-NGEN': 0.0018891948,\n",
              " 'NAG-GEN': 0.013686359,\n",
              " 'NAG-NGEN': 0.0017242465,\n",
              " 'OAG-GEN': 0.9437853,\n",
              " 'OAG-NGEN': 0.027810896}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeYXTUALk17k",
        "colab_type": "code",
        "outputId": "831abbcb-4e2e-4b4a-e655-4ba31e41345b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "compute_dict_marginals(preds_probs[0], task_labels)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.compute_dict_marginals.<locals>.<lambda>>,\n",
              "            {'task_0': defaultdict(float,\n",
              "                         {'OAG': array([0.9437853 , 0.0278109 , 0.01368636, 0.00172425, 0.01110406,\n",
              "                                 0.00188919], dtype=float32)}),\n",
              "             'task_1': defaultdict(float,\n",
              "                         {'GEN': array([0.9437853 , 0.0278109 , 0.01368636, 0.00172425, 0.01110406,\n",
              "                                 0.00188919], dtype=float32)}),\n",
              "             'task_joint': {'CAG-GEN': 0.011104056,\n",
              "              'CAG-NGEN': 0.0018891948,\n",
              "              'NAG-GEN': 0.013686359,\n",
              "              'NAG-NGEN': 0.0017242465,\n",
              "              'OAG-GEN': 0.9437853,\n",
              "              'OAG-NGEN': 0.027810896}})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qay-TzGzknGj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "0e0b407c-abfc-4df8-d28b-6fb54b6cbe78"
      },
      "source": [
        "df_preds = show_marginal_probs(preds_probs[0], task_labels)\n",
        "df_preds.style.background_gradient(cmap='viridis')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "    #T_ff342d58_991b_11ea_98aa_0242ac1c0002row0_col0 {\n",
              "            background-color:  #440154;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_ff342d58_991b_11ea_98aa_0242ac1c0002row0_col1 {\n",
              "            background-color:  #440256;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_ff342d58_991b_11ea_98aa_0242ac1c0002row0_col2 {\n",
              "            background-color:  #440154;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_ff342d58_991b_11ea_98aa_0242ac1c0002row1_col0 {\n",
              "            background-color:  #440154;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_ff342d58_991b_11ea_98aa_0242ac1c0002row1_col1 {\n",
              "            background-color:  #440154;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_ff342d58_991b_11ea_98aa_0242ac1c0002row1_col2 {\n",
              "            background-color:  #440154;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_ff342d58_991b_11ea_98aa_0242ac1c0002row2_col0 {\n",
              "            background-color:  #efe51c;\n",
              "            color:  #000000;\n",
              "        }    #T_ff342d58_991b_11ea_98aa_0242ac1c0002row2_col1 {\n",
              "            background-color:  #addc30;\n",
              "            color:  #000000;\n",
              "        }    #T_ff342d58_991b_11ea_98aa_0242ac1c0002row2_col2 {\n",
              "            background-color:  #ece51b;\n",
              "            color:  #000000;\n",
              "        }    #T_ff342d58_991b_11ea_98aa_0242ac1c0002row3_col0 {\n",
              "            background-color:  #fde725;\n",
              "            color:  #000000;\n",
              "        }    #T_ff342d58_991b_11ea_98aa_0242ac1c0002row3_col1 {\n",
              "            background-color:  #fde725;\n",
              "            color:  #000000;\n",
              "        }    #T_ff342d58_991b_11ea_98aa_0242ac1c0002row3_col2 {\n",
              "            background-color:  #fde725;\n",
              "            color:  #000000;\n",
              "        }</style><table id=\"T_ff342d58_991b_11ea_98aa_0242ac1c0002\" ><thead>    <tr>        <th class=\"index_name level0\" >task_1</th>        <th class=\"col_heading level0 col0\" >GEN</th>        <th class=\"col_heading level0 col1\" >NGEN</th>        <th class=\"col_heading level0 col2\" >task_0</th>    </tr>    <tr>        <th class=\"index_name level0\" >task_0</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_ff342d58_991b_11ea_98aa_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >CAG</th>\n",
              "                        <td id=\"T_ff342d58_991b_11ea_98aa_0242ac1c0002row0_col0\" class=\"data row0 col0\" >0.011104</td>\n",
              "                        <td id=\"T_ff342d58_991b_11ea_98aa_0242ac1c0002row0_col1\" class=\"data row0 col1\" >0.001889</td>\n",
              "                        <td id=\"T_ff342d58_991b_11ea_98aa_0242ac1c0002row0_col2\" class=\"data row0 col2\" >0.012993</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_ff342d58_991b_11ea_98aa_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >NAG</th>\n",
              "                        <td id=\"T_ff342d58_991b_11ea_98aa_0242ac1c0002row1_col0\" class=\"data row1 col0\" >0.013686</td>\n",
              "                        <td id=\"T_ff342d58_991b_11ea_98aa_0242ac1c0002row1_col1\" class=\"data row1 col1\" >0.001724</td>\n",
              "                        <td id=\"T_ff342d58_991b_11ea_98aa_0242ac1c0002row1_col2\" class=\"data row1 col2\" >0.015411</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_ff342d58_991b_11ea_98aa_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >OAG</th>\n",
              "                        <td id=\"T_ff342d58_991b_11ea_98aa_0242ac1c0002row2_col0\" class=\"data row2 col0\" >0.943785</td>\n",
              "                        <td id=\"T_ff342d58_991b_11ea_98aa_0242ac1c0002row2_col1\" class=\"data row2 col1\" >0.027811</td>\n",
              "                        <td id=\"T_ff342d58_991b_11ea_98aa_0242ac1c0002row2_col2\" class=\"data row2 col2\" >0.971596</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_ff342d58_991b_11ea_98aa_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >task_1</th>\n",
              "                        <td id=\"T_ff342d58_991b_11ea_98aa_0242ac1c0002row3_col0\" class=\"data row3 col0\" >0.968576</td>\n",
              "                        <td id=\"T_ff342d58_991b_11ea_98aa_0242ac1c0002row3_col1\" class=\"data row3 col1\" >0.031424</td>\n",
              "                        <td id=\"T_ff342d58_991b_11ea_98aa_0242ac1c0002row3_col2\" class=\"data row3 col2\" >1.000000</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fe759d75978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-9QOpdiqOW6",
        "colab_type": "code",
        "outputId": "f4fd3d17-c22d-48ab-d901-aeb891369696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "pd.DataFrame({\n",
        "    \"labels\": task_labels,\n",
        "    \"probs\": preds_probs[0]\n",
        "}).assign(\n",
        "    task_0=lambda x: x[\"labels\"].str.split(\"-\", expand=True)[0],\n",
        "    task_1=lambda x: x[\"labels\"].str.split(\"-\", expand=True)[1]\n",
        ").drop(\"labels\", axis=1).pivot_table(index=\"task_0\", columns=\"task_1\", values=\"probs\", aggfunc=\"first\").pipe(add_marginals)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>task_1</th>\n",
              "      <th>GEN</th>\n",
              "      <th>NGEN</th>\n",
              "      <th>task_0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>task_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CAG</th>\n",
              "      <td>0.011104</td>\n",
              "      <td>0.001889</td>\n",
              "      <td>0.012993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NAG</th>\n",
              "      <td>0.013686</td>\n",
              "      <td>0.001724</td>\n",
              "      <td>0.015411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OAG</th>\n",
              "      <td>0.943785</td>\n",
              "      <td>0.027811</td>\n",
              "      <td>0.971596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>task_1</th>\n",
              "      <td>0.968576</td>\n",
              "      <td>0.031424</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "task_1       GEN      NGEN    task_0\n",
              "task_0                              \n",
              "CAG     0.011104  0.001889  0.012993\n",
              "NAG     0.013686  0.001724  0.015411\n",
              "OAG     0.943785  0.027811  0.971596\n",
              "task_1  0.968576  0.031424  1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}