{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TRAC_Experiments_transformers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuVTg8VLViNd",
        "colab_type": "code",
        "outputId": "573bdaf2-57a0-428b-a7df-b06f44600ebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        }
      },
      "source": [
        "%%bash\n",
        "pip install torch transformers tensorboardX"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Collecting transformers\n",
            "  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "Collecting tensorboardX\n",
            "  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Collecting sacremoses\n",
            "  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "Collecting tokenizers==0.5.2\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (45.2.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py): started\n",
            "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=766c3b61e219d8ea8434f8b07cfd97e5884f9c209211a220d80775e302adda22\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers, tensorboardX\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tensorboardX-2.0 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpgcK6edVyt7",
        "colab_type": "code",
        "outputId": "00fb2738-688a-4965-f846-bfb482962bc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKblDQmBV5ky",
        "colab_type": "code",
        "outputId": "e6975208-9c16-48e5-b339-06fc3b787515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%env TRAC_PATH /content/gdrive/My Drive/TRAC2020/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: TRAC_PATH=/content/gdrive/My Drive/TRAC2020/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM-Kk2LHWD5J",
        "colab_type": "code",
        "outputId": "d6fcdabb-e485-4563-b3db-e0469536b887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "%%bash \n",
        "echo \"${TRAC_PATH}\"\n",
        "ls -ltrh \"${TRAC_PATH}/data\"\n",
        "realpath \"${TRAC_PATH}\"\n",
        "ls -ltrh \"${TRAC_PATH}\"/data/**/*"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/TRAC2020/\n",
            "total 4.0K\n",
            "drwx------ 2 root root 4.0K Mar  5 10:20 raw\n",
            "/content/gdrive/My Drive/TRAC2020\n",
            "-rw------- 1 root root  321 Mar  8 16:08 /content/gdrive/My Drive/TRAC2020//data/raw/README.txt\n",
            "\n",
            "/content/gdrive/My Drive/TRAC2020//data/raw/iben:\n",
            "total 565K\n",
            "-rw------- 1 root root  82K Mar  8 16:08 trac2_iben_test.csv\n",
            "-rw------- 1 root root 389K Mar  8 18:08 trac2_iben_train.csv\n",
            "-rw------- 1 root root 1.3K Mar  8 18:08 README.txt\n",
            "-rw------- 1 root root  93K Mar  8 18:08 trac2_iben_dev.csv\n",
            "\n",
            "/content/gdrive/My Drive/TRAC2020//data/raw/hin:\n",
            "total 812K\n",
            "-rw------- 1 root root 174K Mar  8 16:08 trac2_hin_test.csv\n",
            "-rw------- 1 root root 1.3K Mar  8 18:08 README.txt\n",
            "-rw------- 1 root root 126K Mar  8 18:08 trac2_hin_dev.csv\n",
            "-rw------- 1 root root 511K Mar  8 18:08 trac2_hin_train.csv\n",
            "\n",
            "/content/gdrive/My Drive/TRAC2020//data/raw/eng:\n",
            "total 908K\n",
            "-rw------- 1 root root 281K Mar  8 16:08 trac2_eng_test.csv\n",
            "-rw------- 1 root root 1.3K Mar  8 18:08 README.txt\n",
            "-rw------- 1 root root 127K Mar  8 18:08 trac2_eng_dev.csv\n",
            "-rw------- 1 root root 499K Mar  8 18:08 trac2_eng_train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hshhLiWsrNwj",
        "colab_type": "text"
      },
      "source": [
        "# Generate data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tLA7i6-WI6W",
        "colab_type": "code",
        "outputId": "bc0b0347-84ca-49de-8154-5c8dca8a8085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%bash\n",
        "python \"${TRAC_PATH}\"/src/generate_data.py --normalize --all_langs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "train\n",
            "./ENG/Sub-task A/train.tsv\n",
            "./ENG/Sub-task A/train.json\n",
            "./ENG/Sub-task B/train.tsv\n",
            "./ENG/Sub-task B/train.json\n",
            "./ENG/Sub-task C/train.tsv\n",
            "./ENG/Sub-task C/train.json\n",
            "./IBEN/Sub-task A/train.tsv\n",
            "./IBEN/Sub-task A/train.json\n",
            "./IBEN/Sub-task B/train.tsv\n",
            "./IBEN/Sub-task B/train.json\n",
            "./IBEN/Sub-task C/train.tsv\n",
            "./IBEN/Sub-task C/train.json\n",
            "./HIN/Sub-task A/train.tsv\n",
            "./HIN/Sub-task A/train.json\n",
            "./HIN/Sub-task B/train.tsv\n",
            "./HIN/Sub-task B/train.json\n",
            "./HIN/Sub-task C/train.tsv\n",
            "./HIN/Sub-task C/train.json\n",
            "dev\n",
            "./ENG/Sub-task A/dev.tsv\n",
            "./ENG/Sub-task A/dev.json\n",
            "./ENG/Sub-task B/dev.tsv\n",
            "./ENG/Sub-task B/dev.json\n",
            "./ENG/Sub-task C/dev.tsv\n",
            "./ENG/Sub-task C/dev.json\n",
            "./IBEN/Sub-task A/dev.tsv\n",
            "./IBEN/Sub-task A/dev.json\n",
            "./IBEN/Sub-task B/dev.tsv\n",
            "./IBEN/Sub-task B/dev.json\n",
            "./IBEN/Sub-task C/dev.tsv\n",
            "./IBEN/Sub-task C/dev.json\n",
            "./HIN/Sub-task A/dev.tsv\n",
            "./HIN/Sub-task A/dev.json\n",
            "./HIN/Sub-task B/dev.tsv\n",
            "./HIN/Sub-task B/dev.json\n",
            "./HIN/Sub-task C/dev.tsv\n",
            "./HIN/Sub-task C/dev.json\n",
            "test\n",
            "./ENG/Sub-task A/test.tsv\n",
            "./ENG/Sub-task A/test.json\n",
            "./ENG/Sub-task B/test.tsv\n",
            "./ENG/Sub-task B/test.json\n",
            "./ENG/Sub-task C/test.tsv\n",
            "./ENG/Sub-task C/test.json\n",
            "./IBEN/Sub-task A/test.tsv\n",
            "./IBEN/Sub-task A/test.json\n",
            "./IBEN/Sub-task B/test.tsv\n",
            "./IBEN/Sub-task B/test.json\n",
            "./IBEN/Sub-task C/test.tsv\n",
            "./IBEN/Sub-task C/test.json\n",
            "./HIN/Sub-task A/test.tsv\n",
            "./HIN/Sub-task A/test.json\n",
            "./HIN/Sub-task B/test.tsv\n",
            "./HIN/Sub-task B/test.json\n",
            "./HIN/Sub-task C/test.tsv\n",
            "./HIN/Sub-task C/test.json\n",
            "./ALL/Sub-task A/train.tsv\n",
            "./ALL/Sub-task A/train.json\n",
            "./ALL/Sub-task B/train.tsv\n",
            "./ALL/Sub-task B/train.json\n",
            "./ALL/Sub-task C/train.tsv\n",
            "./ALL/Sub-task C/train.json\n",
            "./ALL/Sub-task A/dev.tsv\n",
            "./ALL/Sub-task A/dev.json\n",
            "./ALL/Sub-task B/dev.tsv\n",
            "./ALL/Sub-task B/dev.json\n",
            "./ALL/Sub-task C/dev.tsv\n",
            "./ALL/Sub-task C/dev.json\n",
            "./ALL/Sub-task A/test.tsv\n",
            "./ALL/Sub-task A/test.json\n",
            "./ALL/Sub-task B/test.tsv\n",
            "./ALL/Sub-task B/test.json\n",
            "./ALL/Sub-task C/test.tsv\n",
            "./ALL/Sub-task C/test.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K17LWok3jvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNzdYun93QFo",
        "colab_type": "code",
        "outputId": "54ecf07c-aca6-4b7a-8e1e-f2a1e8ef167d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%env TRAINING_SCRIPT {os.environ['TRAC_PATH']}/src/run_experiment_transformers.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: TRAINING_SCRIPT=/content/gdrive/My Drive/TRAC2020//src/run_experiment_transformers.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reciAig53eGG",
        "colab_type": "code",
        "outputId": "aea65b5e-89b4-48a4-9369-2a083568c755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%bash\n",
        "echo \"${TRAINING_SCRIPT}\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/TRAC2020//src/run_experiment_transformers.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLHYsWUCTzQV",
        "colab_type": "code",
        "outputId": "32f67fd9-6b31-4408-bd61-3843d6296236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%bash\n",
        "python \"${TRAINING_SCRIPT}\" --help"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: run_experiment_transformers.py [-h] --data_dir DATA_DIR\n",
            "                                      --bert_model_type BERT_MODEL_TYPE --task\n",
            "                                      TASK --lang LANG --output_dir OUTPUT_DIR\n",
            "                                      [--cache_dir CACHE_DIR]\n",
            "                                      [--max_seq_length MAX_SEQ_LENGTH]\n",
            "                                      [--do_train] [--do_eval]\n",
            "                                      [--evaluate_during_training]\n",
            "                                      [--do_lower_case]\n",
            "                                      [--train_batch_size TRAIN_BATCH_SIZE]\n",
            "                                      [--eval_batch_size EVAL_BATCH_SIZE]\n",
            "                                      [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
            "                                      [--learning_rate LEARNING_RATE]\n",
            "                                      [--weight_decay WEIGHT_DECAY]\n",
            "                                      [--adam_epsilon ADAM_EPSILON]\n",
            "                                      [--max_grad_norm MAX_GRAD_NORM]\n",
            "                                      [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
            "                                      [--max_steps MAX_STEPS]\n",
            "                                      [--warmup_steps WARMUP_STEPS]\n",
            "                                      [--logging_steps LOGGING_STEPS]\n",
            "                                      [--save_steps SAVE_STEPS]\n",
            "                                      [--eval_all_checkpoints] [--no_cuda]\n",
            "                                      [--overwrite_output_dir]\n",
            "                                      [--overwrite_cache] [--seed SEED]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --data_dir DATA_DIR   The input data dir. Should contain the .tsv files (or\n",
            "                        other data files) for the task.\n",
            "  --bert_model_type BERT_MODEL_TYPE\n",
            "                        Bert Model type selected in the list:\n",
            "  --task TASK           The name of the task to train selected in the list:\n",
            "                        task_1, task_2, task_3\n",
            "  --lang LANG           The name of the lang to train selected in the list:\n",
            "                        EN, DE, HI\n",
            "  --output_dir OUTPUT_DIR\n",
            "                        The output directory where the model predictions and\n",
            "                        checkpoints will be written.\n",
            "  --cache_dir CACHE_DIR\n",
            "                        Where do you want to store the pre-trained models\n",
            "                        downloaded from s3\n",
            "  --max_seq_length MAX_SEQ_LENGTH\n",
            "                        The maximum total input sequence length after\n",
            "                        tokenization. Sequences longer than this will be\n",
            "                        truncated, sequences shorter will be padded.\n",
            "  --do_train            Whether to run training.\n",
            "  --do_eval             Whether to run eval on the dev set.\n",
            "  --evaluate_during_training\n",
            "                        Rul evaluation during training at each logging step.\n",
            "  --do_lower_case       Set this flag if you are using an uncased model.\n",
            "  --train_batch_size TRAIN_BATCH_SIZE\n",
            "                        Batch size per GPU/CPU for training.\n",
            "  --eval_batch_size EVAL_BATCH_SIZE\n",
            "                        Batch size per GPU/CPU for evaluation.\n",
            "  --gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS\n",
            "                        Number of updates steps to accumulate before\n",
            "                        performing a backward/update pass.\n",
            "  --learning_rate LEARNING_RATE\n",
            "                        The initial learning rate for Adam.\n",
            "  --weight_decay WEIGHT_DECAY\n",
            "                        Weight deay if we apply some.\n",
            "  --adam_epsilon ADAM_EPSILON\n",
            "                        Epsilon for Adam optimizer.\n",
            "  --max_grad_norm MAX_GRAD_NORM\n",
            "                        Max gradient norm.\n",
            "  --num_train_epochs NUM_TRAIN_EPOCHS\n",
            "                        Total number of training epochs to perform.\n",
            "  --max_steps MAX_STEPS\n",
            "                        If > 0: set total number of training steps to perform.\n",
            "                        Override num_train_epochs.\n",
            "  --warmup_steps WARMUP_STEPS\n",
            "                        Linear warmup over warmup_steps.\n",
            "  --logging_steps LOGGING_STEPS\n",
            "                        Log every X updates steps.\n",
            "  --save_steps SAVE_STEPS\n",
            "                        Save checkpoint every X updates steps.\n",
            "  --eval_all_checkpoints\n",
            "                        Evaluate all checkpoints starting with the same prefix\n",
            "                        as model_name ending and ending with step number\n",
            "  --no_cuda             Avoid using CUDA when available\n",
            "  --overwrite_output_dir\n",
            "                        Overwrite the content of the output directory\n",
            "  --overwrite_cache     Overwrite the cached training and evaluation sets\n",
            "  --seed SEED           random seed for initialization\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuiCojl3h-dq",
        "colab_type": "text"
      },
      "source": [
        "# English"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--jDARYR5VDT",
        "colab_type": "text"
      },
      "source": [
        "## bert-base-cased"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjwd1ny1UpCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task A\"\n",
        "LANG=\"ENG\"\n",
        "MODEL=\"bert-base-cased\"\n",
        "python \"${TRAINING_SCRIPT}\" \\\n",
        "--data_dir \"./${LANG}/${TASK}\" \\\n",
        "--bert_model_type \"${MODEL}\" \\\n",
        "--task \"${TASK}\" \\\n",
        "--lang ${LANG} \\\n",
        "--output_dir \"./${LANG}/${TASK}/output/${MODEL}\" \\\n",
        "--cache_dir \"./${LANG}/${TASK}\" \\\n",
        "--num_train_epochs 5 \\\n",
        "--train_batch_size 32 \\\n",
        "--eval_batch_size 32 \\\n",
        "--save_steps 50 \\\n",
        "--logging_steps 5 \\\n",
        "--gradient_accumulation_steps 2 \\\n",
        "\n",
        "tar -czvf \"./${LANG}/${TASK}/output/${MODEL}.tar.gz\" \"./${LANG}/${TASK}/output/${MODEL}\"/{*.tsv,*.json,events.*,model/config.json}\n",
        "curl \"https://bashupload.com/${LANG}_${TASK}_${MODEL}.tar.gz\" --data-binary @\"./${LANG}/${TASK}/output/${MODEL}.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2iXQ1dRVOUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task B\"\n",
        "LANG=\"ENG\"\n",
        "MODEL=\"bert-base-cased\"\n",
        "python \"${TRAINING_SCRIPT}\" \\\n",
        "--data_dir \"./${LANG}/${TASK}\" \\\n",
        "--bert_model_type \"${MODEL}\" \\\n",
        "--task \"${TASK}\" \\\n",
        "--lang ${LANG} \\\n",
        "--output_dir \"./${LANG}/${TASK}/output/${MODEL}\" \\\n",
        "--cache_dir \"./${LANG}/${TASK}\" \\\n",
        "--num_train_epochs 5 \\\n",
        "--train_batch_size 32 \\\n",
        "--eval_batch_size 32 \\\n",
        "--save_steps 50 \\\n",
        "--logging_steps 5 \\\n",
        "--gradient_accumulation_steps 2 \\\n",
        "\n",
        "tar -czvf \"./${LANG}/${TASK}/output/${MODEL}.tar.gz\" \"./${LANG}/${TASK}/output/${MODEL}\"/{*.tsv,*.json,events.*,model/config.json}\n",
        "curl \"https://bashupload.com/${LANG}_${TASK}_${MODEL}.tar.gz\" --data-binary @\"./${LANG}/${TASK}/output/${MODEL}.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_wd33YPipfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task C\"\n",
        "LANG=\"ENG\"\n",
        "MODEL=\"bert-base-cased\"\n",
        "python \"${TRAINING_SCRIPT}\" \\\n",
        "--data_dir \"./${LANG}/${TASK}\" \\\n",
        "--bert_model_type \"${MODEL}\" \\\n",
        "--task \"${TASK}\" \\\n",
        "--lang ${LANG} \\\n",
        "--output_dir \"./${LANG}/${TASK}/output/${MODEL}\" \\\n",
        "--cache_dir \"./${LANG}/${TASK}\" \\\n",
        "--num_train_epochs 5 \\\n",
        "--train_batch_size 32 \\\n",
        "--eval_batch_size 32 \\\n",
        "--save_steps 50 \\\n",
        "--logging_steps 5 \\\n",
        "--gradient_accumulation_steps 2 \\\n",
        "\n",
        "tar -czvf \"./${LANG}/${TASK}/output/${MODEL}.tar.gz\" \"./${LANG}/${TASK}/output/${MODEL}\"/{*.tsv,*.json,events.*,model/config.json}\n",
        "curl \"https://bashupload.com/${LANG}_${TASK}_${MODEL}.tar.gz\" --data-binary @\"./${LANG}/${TASK}/output/${MODEL}.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW4x7kmriG3y",
        "colab_type": "text"
      },
      "source": [
        "## bert-base-uncased"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEz1mhMgVpgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task A\"\n",
        "LANG=\"ENG\"\n",
        "MODEL=\"bert-base-uncased\"\n",
        "python \"${TRAINING_SCRIPT}\" \\\n",
        "--data_dir \"./${LANG}/${TASK}\" \\\n",
        "--bert_model_type \"${MODEL}\" \\\n",
        "--do_lower_case \\\n",
        "--task \"${TASK}\" \\\n",
        "--lang ${LANG} \\\n",
        "--output_dir \"./${LANG}/${TASK}/output/${MODEL}\" \\\n",
        "--cache_dir \"./${LANG}/${TASK}\" \\\n",
        "--num_train_epochs 5 \\\n",
        "--train_batch_size 32 \\\n",
        "--eval_batch_size 32 \\\n",
        "--save_steps 50 \\\n",
        "--logging_steps 5 \\\n",
        "--gradient_accumulation_steps 2 \\\n",
        "\n",
        "tar -czvf \"./${LANG}/${TASK}/output/${MODEL}.tar.gz\" \"./${LANG}/${TASK}/output/${MODEL}\"/{*.tsv,*.json,events.*,model/config.json}\n",
        "curl \"https://bashupload.com/${LANG}_${TASK}_${MODEL}.tar.gz\" --data-binary @\"./${LANG}/${TASK}/output/${MODEL}.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJF_a8vDkrRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task B\"\n",
        "LANG=\"ENG\"\n",
        "MODEL=\"bert-base-uncased\"\n",
        "python \"${TRAINING_SCRIPT}\" \\\n",
        "--data_dir \"./${LANG}/${TASK}\" \\\n",
        "--bert_model_type \"${MODEL}\" \\\n",
        "--do_lower_case \\\n",
        "--task \"${TASK}\" \\\n",
        "--lang ${LANG} \\\n",
        "--output_dir \"./${LANG}/${TASK}/output/${MODEL}\" \\\n",
        "--cache_dir \"./${LANG}/${TASK}\" \\\n",
        "--num_train_epochs 5 \\\n",
        "--train_batch_size 32 \\\n",
        "--eval_batch_size 32 \\\n",
        "--save_steps 50 \\\n",
        "--logging_steps 5 \\\n",
        "--gradient_accumulation_steps 2 \\\n",
        "\n",
        "tar -czvf \"./${LANG}/${TASK}/output/${MODEL}.tar.gz\" \"./${LANG}/${TASK}/output/${MODEL}\"/{*.tsv,*.json,events.*,model/config.json}\n",
        "curl \"https://bashupload.com/${LANG}_${TASK}_${MODEL}.tar.gz\" --data-binary @\"./${LANG}/${TASK}/output/${MODEL}.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snwam01k5K41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task C\"\n",
        "LANG=\"ENG\"\n",
        "MODEL=\"bert-base-uncased\"\n",
        "python \"${TRAINING_SCRIPT}\" \\\n",
        "--data_dir \"./${LANG}/${TASK}\" \\\n",
        "--bert_model_type \"${MODEL}\" \\\n",
        "--do_lower_case \\\n",
        "--task \"${TASK}\" \\\n",
        "--lang ${LANG} \\\n",
        "--output_dir \"./${LANG}/${TASK}/output/${MODEL}\" \\\n",
        "--cache_dir \"./${LANG}/${TASK}\" \\\n",
        "--num_train_epochs 5 \\\n",
        "--train_batch_size 32 \\\n",
        "--eval_batch_size 32 \\\n",
        "--save_steps 50 \\\n",
        "--logging_steps 5 \\\n",
        "--gradient_accumulation_steps 2 \\\n",
        "\n",
        "tar -czvf \"./${LANG}/${TASK}/output/${MODEL}.tar.gz\" \"./${LANG}/${TASK}/output/${MODEL}\"/{*.tsv,*.json,events.*,model/config.json}\n",
        "curl \"https://bashupload.com/${LANG}_${TASK}_${MODEL}.tar.gz\" --data-binary @\"./${LANG}/${TASK}/output/${MODEL}.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4m5lPEiBBJ_",
        "colab_type": "text"
      },
      "source": [
        "# Hindi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoyVh94X5PJI",
        "colab_type": "text"
      },
      "source": [
        "## bert-base-multilingual-uncased"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rzn-iaYQ6kD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task A\"\n",
        "LANG=\"HIN\"\n",
        "MODEL=\"bert-base-multilingual-uncased\"\n",
        "python \"${TRAINING_SCRIPT}\" \\\n",
        "--data_dir \"./${LANG}/${TASK}\" \\\n",
        "--bert_model_type \"${MODEL}\" \\\n",
        "--do_lower_case \\\n",
        "--task \"${TASK}\" \\\n",
        "--lang ${LANG} \\\n",
        "--output_dir \"./${LANG}/${TASK}/output/${MODEL}\" \\\n",
        "--cache_dir \"./${LANG}/${TASK}\" \\\n",
        "--num_train_epochs 5 \\\n",
        "--train_batch_size 32 \\\n",
        "--eval_batch_size 32 \\\n",
        "--save_steps 50 \\\n",
        "--logging_steps 5 \\\n",
        "--gradient_accumulation_steps 2 \\\n",
        "\n",
        "tar -czvf \"./${LANG}/${TASK}/output/${MODEL}.tar.gz\" \"./${LANG}/${TASK}/output/${MODEL}\"/{*.tsv,*.json,events.*,model/config.json}\n",
        "curl \"https://bashupload.com/${LANG}_${TASK}_${MODEL}.tar.gz\" --data-binary @\"./${LANG}/${TASK}/output/${MODEL}.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1nJOivHBo8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task B\"\n",
        "LANG=\"HIN\"\n",
        "MODEL=\"bert-base-multilingual-uncased\"\n",
        "python \"${TRAINING_SCRIPT}\" \\\n",
        "--data_dir \"./${LANG}/${TASK}\" \\\n",
        "--bert_model_type \"${MODEL}\" \\\n",
        "--do_lower_case \\\n",
        "--task \"${TASK}\" \\\n",
        "--lang ${LANG} \\\n",
        "--output_dir \"./${LANG}/${TASK}/output/${MODEL}\" \\\n",
        "--cache_dir \"./${LANG}/${TASK}\" \\\n",
        "--num_train_epochs 5 \\\n",
        "--train_batch_size 32 \\\n",
        "--eval_batch_size 32 \\\n",
        "--save_steps 50 \\\n",
        "--logging_steps 5 \\\n",
        "--gradient_accumulation_steps 2 \\\n",
        "\n",
        "tar -czvf \"./${LANG}/${TASK}/output/${MODEL}.tar.gz\" \"./${LANG}/${TASK}/output/${MODEL}\"/{*.tsv,*.json,events.*,model/config.json}\n",
        "curl \"https://bashupload.com/${LANG}_${TASK}_${MODEL}.tar.gz\" --data-binary @\"./${LANG}/${TASK}/output/${MODEL}.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJxG15PV5rPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task C\"\n",
        "LANG=\"HIN\"\n",
        "MODEL=\"bert-base-multilingual-uncased\"\n",
        "python \"${TRAINING_SCRIPT}\" \\\n",
        "--data_dir \"./${LANG}/${TASK}\" \\\n",
        "--bert_model_type \"${MODEL}\" \\\n",
        "--do_lower_case \\\n",
        "--task \"${TASK}\" \\\n",
        "--lang ${LANG} \\\n",
        "--output_dir \"./${LANG}/${TASK}/output/${MODEL}\" \\\n",
        "--cache_dir \"./${LANG}/${TASK}\" \\\n",
        "--num_train_epochs 5 \\\n",
        "--train_batch_size 32 \\\n",
        "--eval_batch_size 32 \\\n",
        "--save_steps 50 \\\n",
        "--logging_steps 5 \\\n",
        "--gradient_accumulation_steps 2 \\\n",
        "\n",
        "tar -czvf \"./${LANG}/${TASK}/output/${MODEL}.tar.gz\" \"./${LANG}/${TASK}/output/${MODEL}\"/{*.tsv,*.json,events.*,model/config.json}\n",
        "curl \"https://bashupload.com/${LANG}_${TASK}_${MODEL}.tar.gz\" --data-binary @\"./${LANG}/${TASK}/output/${MODEL}.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0blaIwr_RLV5",
        "colab_type": "text"
      },
      "source": [
        "# Bengali"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFpZN_3w5_ih",
        "colab_type": "text"
      },
      "source": [
        "## bert-base-multilingual-uncased"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK12SX8_RRg-",
        "colab_type": "code",
        "outputId": "c2591f05-221b-4fac-d854-9efaeea02ed8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task A\"\n",
        "LANG=\"IBEN\"\n",
        "MODEL=\"bert-base-multilingual-uncased\"\n",
        "python \"${TRAINING_SCRIPT}\" \\\n",
        "--data_dir \"./${LANG}/${TASK}\" \\\n",
        "--bert_model_type \"${MODEL}\" \\\n",
        "--do_lower_case \\\n",
        "--task \"${TASK}\" \\\n",
        "--lang ${LANG} \\\n",
        "--output_dir \"./${LANG}/${TASK}/output/${MODEL}\" \\\n",
        "--cache_dir \"./${LANG}/${TASK}\" \\\n",
        "--num_train_epochs 5 \\\n",
        "--train_batch_size 32 \\\n",
        "--eval_batch_size 32 \\\n",
        "--save_steps 50 \\\n",
        "--logging_steps 5 \\\n",
        "--gradient_accumulation_steps 2 \\\n",
        "\n",
        "tar -czvf \"./${LANG}/${TASK}/output/${MODEL}.tar.gz\" \"./${LANG}/${TASK}/output/${MODEL}\"/{*.tsv,*.json,events.*,model/config.json}\n",
        "curl \"https://bashupload.com/${LANG}_${TASK}_${MODEL}.tar.gz\" --data-binary @\"./${LANG}/${TASK}/output/${MODEL}.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Process is terminated.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCX2BLPKRZVZ",
        "colab_type": "code",
        "outputId": "8d38fc47-8e7e-45ce-ef00-95c671bafd0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task B\"\n",
        "LANG=\"IBEN\"\n",
        "MODEL=\"bert-base-multilingual-uncased\"\n",
        "python \"${TRAINING_SCRIPT}\" \\\n",
        "--data_dir \"./${LANG}/${TASK}\" \\\n",
        "--bert_model_type \"${MODEL}\" \\\n",
        "--do_lower_case \\\n",
        "--task \"${TASK}\" \\\n",
        "--lang ${LANG} \\\n",
        "--output_dir \"./${LANG}/${TASK}/output/${MODEL}\" \\\n",
        "--cache_dir \"./${LANG}/${TASK}\" \\\n",
        "--num_train_epochs 5 \\\n",
        "--train_batch_size 32 \\\n",
        "--eval_batch_size 32 \\\n",
        "--save_steps 50 \\\n",
        "--logging_steps 5 \\\n",
        "--gradient_accumulation_steps 2 \\\n",
        "\n",
        "tar -czvf \"./${LANG}/${TASK}/output/${MODEL}.tar.gz\" \"./${LANG}/${TASK}/output/${MODEL}\"/{*.tsv,*.json,events.*,model/config.json}\n",
        "curl \"https://bashupload.com/${LANG}_${TASK}_${MODEL}.tar.gz\" --data-binary @\"./${LANG}/${TASK}/output/${MODEL}.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Process is terminated.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYl69PhJ55cD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task C\"\n",
        "LANG=\"IBEN\"\n",
        "MODEL=\"bert-base-multilingual-uncased\"\n",
        "python \"${TRAINING_SCRIPT}\" \\\n",
        "--data_dir \"./${LANG}/${TASK}\" \\\n",
        "--bert_model_type \"${MODEL}\" \\\n",
        "--do_lower_case \\\n",
        "--task \"${TASK}\" \\\n",
        "--lang ${LANG} \\\n",
        "--output_dir \"./${LANG}/${TASK}/output/${MODEL}\" \\\n",
        "--cache_dir \"./${LANG}/${TASK}\" \\\n",
        "--num_train_epochs 5 \\\n",
        "--train_batch_size 32 \\\n",
        "--eval_batch_size 32 \\\n",
        "--save_steps 50 \\\n",
        "--logging_steps 5 \\\n",
        "--gradient_accumulation_steps 2 \\\n",
        "\n",
        "tar -czvf \"./${LANG}/${TASK}/output/${MODEL}.tar.gz\" \"./${LANG}/${TASK}/output/${MODEL}\"/{*.tsv,*.json,events.*,model/config.json}\n",
        "curl \"https://bashupload.com/${LANG}_${TASK}_${MODEL}.tar.gz\" --data-binary @\"./${LANG}/${TASK}/output/${MODEL}.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5aBnFaK4jNYY"
      },
      "source": [
        "# ALL Langs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jQhiTA0ojNYh"
      },
      "source": [
        "## bert-base-multilingual-uncased"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c2591f05-221b-4fac-d854-9efaeea02ed8",
        "id": "IavejAzDjNYj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task A\"\n",
        "LANG=\"ALL\"\n",
        "MODEL=\"bert-base-multilingual-uncased\"\n",
        "python \"${TRAINING_SCRIPT}\" \\\n",
        "--data_dir \"./${LANG}/${TASK}\" \\\n",
        "--bert_model_type \"${MODEL}\" \\\n",
        "--do_lower_case \\\n",
        "--task \"${TASK}\" \\\n",
        "--lang ${LANG} \\\n",
        "--output_dir \"./${LANG}/${TASK}/output/${MODEL}\" \\\n",
        "--cache_dir \"./${LANG}/${TASK}\" \\\n",
        "--num_train_epochs 5 \\\n",
        "--train_batch_size 32 \\\n",
        "--eval_batch_size 32 \\\n",
        "--save_steps 50 \\\n",
        "--logging_steps 5 \\\n",
        "--gradient_accumulation_steps 2 \\\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Process is terminated.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ2MxZmTjeP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task A\"\n",
        "LANG=\"ALL\"\n",
        "MODEL=\"bert-base-multilingual-uncased\"\n",
        "\n",
        "tar -czvf \"./${LANG}/${TASK}/output/${MODEL}.tar.gz\" \"./${LANG}/${TASK}/output/${MODEL}\"/{*.tsv,*.json,events.*,model/config.json}\n",
        "curl \"https://bashupload.com/${LANG}_${TASK}_${MODEL}.tar.gz\" --data-binary @\"./${LANG}/${TASK}/output/${MODEL}.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "elT1QmcGjNYr",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task B\"\n",
        "LANG=\"ALL\"\n",
        "MODEL=\"bert-base-multilingual-uncased\"\n",
        "python \"${TRAINING_SCRIPT}\" \\\n",
        "--data_dir \"./${LANG}/${TASK}\" \\\n",
        "--bert_model_type \"${MODEL}\" \\\n",
        "--do_lower_case \\\n",
        "--task \"${TASK}\" \\\n",
        "--lang ${LANG} \\\n",
        "--output_dir \"./${LANG}/${TASK}/output/${MODEL}\" \\\n",
        "--cache_dir \"./${LANG}/${TASK}\" \\\n",
        "--num_train_epochs 5 \\\n",
        "--train_batch_size 32 \\\n",
        "--eval_batch_size 32 \\\n",
        "--save_steps 50 \\\n",
        "--logging_steps 5 \\\n",
        "--gradient_accumulation_steps 2 \\\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC4_c2UhjlIU",
        "colab_type": "code",
        "outputId": "5da386c2-f9bb-4f57-f021-184af64a0b58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task B\"\n",
        "LANG=\"ALL\"\n",
        "MODEL=\"bert-base-multilingual-uncased\"\n",
        "\n",
        "tar -czvf \"./${LANG}/${TASK}/output/${MODEL}.tar.gz\" \"./${LANG}/${TASK}/output/${MODEL}\"/{*.tsv,*.json,events.*,model/config.json}\n",
        "curl \"https://bashupload.com/${LANG}_${TASK}_${MODEL}.tar.gz\" --data-binary @\"./${LANG}/${TASK}/output/${MODEL}.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./ALL/Sub-task B/output/bert-base-multilingual-uncased/dev.tsv\n",
            "./ALL/Sub-task B/output/bert-base-multilingual-uncased/test.tsv\n",
            "./ALL/Sub-task B/output/bert-base-multilingual-uncased/train.tsv\n",
            "./ALL/Sub-task B/output/bert-base-multilingual-uncased/dev_results.json\n",
            "./ALL/Sub-task B/output/bert-base-multilingual-uncased/train_results.json\n",
            "./ALL/Sub-task B/output/bert-base-multilingual-uncased/events.out.tfevents.1584101557.31bd5a61e5e7\n",
            "./ALL/Sub-task B/output/bert-base-multilingual-uncased/model/config.json\n",
            "\n",
            "Uploaded 1 file, 390947 bytes\n",
            "\n",
            "wget https://bashupload.com/fKjUQ/qm08V.gz\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  381k    0    77  100  381k     66   328k  0:00:01  0:00:01 --:--:--  328k\r100  381k    0    77  100  381k     66   328k  0:00:01  0:00:01 --:--:--  328k\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5KfvdQ-rjNYu",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task C\"\n",
        "LANG=\"ALL\"\n",
        "MODEL=\"bert-base-multilingual-uncased\"\n",
        "python \"${TRAINING_SCRIPT}\" \\\n",
        "--data_dir \"./${LANG}/${TASK}\" \\\n",
        "--bert_model_type \"${MODEL}\" \\\n",
        "--do_lower_case \\\n",
        "--task \"${TASK}\" \\\n",
        "--lang ${LANG} \\\n",
        "--output_dir \"./${LANG}/${TASK}/output/${MODEL}\" \\\n",
        "--cache_dir \"./${LANG}/${TASK}\" \\\n",
        "--num_train_epochs 5 \\\n",
        "--train_batch_size 32 \\\n",
        "--eval_batch_size 32 \\\n",
        "--save_steps 50 \\\n",
        "--logging_steps 5 \\\n",
        "--gradient_accumulation_steps 2 \\\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTNfx_NHjpmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task C\"\n",
        "LANG=\"ALL\"\n",
        "MODEL=\"bert-base-multilingual-uncased\"\n",
        "\n",
        "tar -czvf \"./${LANG}/${TASK}/output/${MODEL}.tar.gz\" \"./${LANG}/${TASK}/output/${MODEL}\"/{*.tsv,*.json,events.*,model/config.json}\n",
        "curl \"https://bashupload.com/${LANG}_${TASK}_${MODEL}.tar.gz\" --data-binary @\"./${LANG}/${TASK}/output/${MODEL}.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUlp4T8PjURU",
        "colab_type": "text"
      },
      "source": [
        "# Upload outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjDJ0fGXtTFh",
        "colab_type": "code",
        "outputId": "bddf3605-a53b-4d49-ceba-46424bfff11f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task B\"\n",
        "LANG=\"IBEN\"\n",
        "MODEL=\"bert-base-multilingual-uncased\"\n",
        "tar -czvf \"./${LANG}/${TASK}/output/${MODEL}.tar.gz\" \"./${LANG}/${TASK}/output/${MODEL}\"/{*.tsv,*.json,events.*,model/config.json}\n",
        "curl \"https://bashupload.com/${LANG}_${TASK}_${MODEL}.tar.gz\" --data-binary @\"./${LANG}/${TASK}/output/${MODEL}.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./IBEN/Sub-task B/output/bert-base-multilingual-uncased/dev.tsv\n",
            "./IBEN/Sub-task B/output/bert-base-multilingual-uncased/test.tsv\n",
            "./IBEN/Sub-task B/output/bert-base-multilingual-uncased/train.tsv\n",
            "./IBEN/Sub-task B/output/bert-base-multilingual-uncased/dev_results.json\n",
            "./IBEN/Sub-task B/output/bert-base-multilingual-uncased/train_results.json\n",
            "./IBEN/Sub-task B/output/bert-base-multilingual-uncased/events.out.tfevents.1583760702.a383a90e8857\n",
            "./IBEN/Sub-task B/output/bert-base-multilingual-uncased/model/config.json\n",
            "\n",
            "Uploaded 1 file, 127689 bytes\n",
            "\n",
            "wget https://bashupload.com/Q9lXk/XPXaU.gz\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  124k    0    77  100  124k    777  1259k --:--:-- --:--:-- --:--:-- 1260k\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xb_3bqt-woS",
        "colab_type": "code",
        "outputId": "4fae94f1-9edc-4ef6-a3c8-6c13d2018af3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task A\"\n",
        "LANG=\"ENG\"\n",
        "MODEL=\"bert-base-cased\"\n",
        "curl \"https://bashupload.com/${LANG}_${TASK}_${MODEL}.tar.gz\" --data-binary @\"./${LANG}/${TASK}/output/${MODEL}.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Uploaded 1 file, 184901 bytes\n",
            "\n",
            "wget https://bashupload.com/tU737/QBS82.gz\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r 26  180k    0     0   26 49152      0   480k --:--:-- --:--:-- --:--:--  475k\r100  180k    0    77  100  180k    583  1367k --:--:-- --:--:-- --:--:-- 1358k\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z3SYpxE3OtE",
        "colab_type": "code",
        "outputId": "37eb7fa3-36de-4542-eef1-55434cb44764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "%%bash\n",
        "TASK=\"Sub-task A\"\n",
        "LANG=\"ENG\"\n",
        "MODEL=\"bert-base-cased\"\n",
        "tar -tzf \"./${LANG}/${TASK}/output/${MODEL}.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./ENG/Sub-task A/output/bert-base-cased/dev.tsv\n",
            "./ENG/Sub-task A/output/bert-base-cased/test.tsv\n",
            "./ENG/Sub-task A/output/bert-base-cased/train.tsv\n",
            "./ENG/Sub-task A/output/bert-base-cased/dev_results.json\n",
            "./ENG/Sub-task A/output/bert-base-cased/train_results.json\n",
            "./ENG/Sub-task A/output/bert-base-cased/events.out.tfevents.1583741922.a383a90e8857\n",
            "./ENG/Sub-task A/output/bert-base-cased/model/config.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_0cHYvo3ZUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! rm -rf ./ENG/Sub-task\\ B/output/bert-base-cased/checkpoint-* "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ29u3IOck_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}